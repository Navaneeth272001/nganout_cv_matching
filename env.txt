# ====================================================
# LLM Configuration
# ====================================================
# Get your free API key from:
# - OpenAI: https://platform.openai.com/api-keys
# - Perplexity: https://www.perplexity.ai/api
# - DeepSeek: https://platform.deepseek.com/api
# - Local Ollama: http://localhost:11434


OPENAI_API_KEY=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

# LLM Base URL (change this for different providers)
# OpenAI: https://api.openai.com/v1
# Perplexity: https://api.perplexity.ai
# DeepSeek: https://api.deepseek.com
# Local Ollama: http://localhost:11434/v1
OPENAI_BASE_URL=https://api.groq.com/openai/v1
OPENAI_MODEL=llama-3.1-8b-instant

# Model name (must be available from your provider)
# OpenAI: gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# Perplexity: llama-2-70b-chat
# DeepSeek: deepseek-chat
# Local Ollama: llama2, mistral, etc.
# OPENAI_MODEL=gpt-4o-mini

# Server Configuration
PORT=3000
NODE_ENV=development
